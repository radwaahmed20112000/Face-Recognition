{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/radwaahmed20112000/Face-Recognition/blob/main/Face_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Balancing**"
      ],
      "metadata": {
        "id": "_lxaK9aPFopv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rwcn76zThO-A"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjIsTd8ajTHe"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import io\n",
        "zf = zipfile.ZipFile('dataSet.zip')\n",
        "zf.extractall('dataSet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtVWxXQFhTpV"
      },
      "outputs": [],
      "source": [
        "PATH = \"/content/dataSet/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEWceEVBVtJt"
      },
      "source": [
        "Read pmg files of given directory and convert it to matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MAi_jYJmp7BS"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "def load_images_from_folder(folder):\n",
        "    images = []\n",
        "    for i in range(1,11,1):\n",
        "        img = cv2.imread(os.path.join(folder, str(i) + \".pgm\"), 0)\n",
        "        if img is not None:\n",
        "            images.append(img)\n",
        "               \n",
        "    return images"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read each person images and store them in the data matrix"
      ],
      "metadata": {
        "id": "KSW-AgMANgQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_images():\n",
        "  dataset = []\n",
        "  for i in range (1,41,1):\n",
        "    dataset += load_images_from_folder(PATH + \"s\" + str(i) + \"/\");\n",
        "  return dataset"
      ],
      "metadata": {
        "id": "V3QM9kGjNaqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70MsmdQqVWfI"
      },
      "source": [
        "Flatten each image from data matrix into 10304 1d "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCScXUVCsMHR"
      },
      "outputs": [],
      "source": [
        "def flatten_images(rows, dataset):\n",
        "  data = np.zeros((rows, 10304))\n",
        "  for i in range (rows):\n",
        "      image = dataset[i].flatten()\n",
        "      data[i,:] = (image)\n",
        "  return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3D23ISyVFU5"
      },
      "source": [
        "Split data into training and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9PkDCPX22zK"
      },
      "outputs": [],
      "source": [
        "def split(df, label):\n",
        "  #even rows for test\n",
        "  X_test = df.iloc[::2]\n",
        "  Y_test = label[::2]\n",
        "\n",
        "  #odd rows for training\n",
        "  X_train = df.iloc[1::2]\n",
        "  Y_train = label[1::2]\n",
        "\n",
        "  X_train.head(10)\n",
        "  return X_train, Y_train, X_test, Y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data preparation"
      ],
      "metadata": {
        "id": "cZTzKWt6K0mn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_preparation(split_callback):\n",
        "\n",
        "  dataset = read_images()\n",
        "\n",
        "  data = flatten_images(400, dataset)\n",
        "  # Generate labels and dataframe from data matrix\n",
        "  label = []\n",
        "  for i in range(1,41,1):\n",
        "    for j in range(10):\n",
        "      label.append(i);\n",
        "\n",
        "  df = pd.DataFrame(data=data)\n",
        "\n",
        "  return split_callback(df, label)"
      ],
      "metadata": {
        "id": "pgORCyBh-8pj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmQM5G4csbId"
      },
      "source": [
        "Bonus part : Splitting 70% , 30% "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lup0Y7xusqkB"
      },
      "outputs": [],
      "source": [
        "def bonus_split(df, label):\n",
        "\n",
        "  X_train = np.zeros((280,10304))\n",
        "  X_test = np.zeros((120,10304))\n",
        "  Y_train = np.zeros((280))\n",
        "  Y_test = np.zeros((120))\n",
        "\n",
        "  k = 0\n",
        "  j = 0\n",
        "\n",
        "  for i in range(0,400,10):\n",
        "      #first 7 images for train\n",
        "      X_train[j:j+7,: ] = df.iloc[i:i+7,:]\n",
        "      Y_train[j:j+7] = label[i:i+7]\n",
        "      j += 7\n",
        "      #the remaining 3 for test\n",
        "      X_test[k:k+3,:] = df.iloc[i+7:i+10,:]\n",
        "      Y_test[k:k+3]= label[i+7:i+10]\n",
        "      k += 3\n",
        "\n",
        "  X_train = pd.DataFrame(data = X_train)\n",
        "  X_test = pd.DataFrame(data = X_test)\n",
        "\n",
        "  return X_train, Y_train, X_test, Y_test "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2loIN13U8wK"
      },
      "source": [
        "# **LDA**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parameter Initialization"
      ],
      "metadata": {
        "id": "n73E2eLeIapQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Default Values \n",
        "rows = 200              \n",
        "n_of_classes = 40       \n",
        "n_of_eigenvectors = 39  \n",
        "n_of_instances = 5"
      ],
      "metadata": {
        "id": "YzswFjVOi3pU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def intialize_variables(n_rows, classes, instances):\n",
        "  global rows, n_of_classes, n_of_instances\n",
        "  rows = n_rows\n",
        "  n_of_classes = classes\n",
        "  n_of_instances = instances"
      ],
      "metadata": {
        "id": "Qt1_4y8LIk2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_n_of_eigen_vectors(eigen_vectors):\n",
        "  global n_of_eigenvectors\n",
        "  n_of_eigenvectors = eigen_vectors"
      ],
      "metadata": {
        "id": "3MWXd8Hi0JdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-58OlT0aVBTf"
      },
      "source": [
        "Calculate each class mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yvmOhsSLV90"
      },
      "outputs": [],
      "source": [
        "def calculate_means(data):\n",
        "  MUs = np.zeros([n_of_classes, 10304])\n",
        "  k = 0\n",
        "  for i in range(0, rows, n_of_instances):\n",
        "    x = data.iloc[i:i + n_of_instances, :]\n",
        "    m = x.mean()\n",
        "    MUs[k:] = m\n",
        "    k += 1\n",
        "  return MUs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bm4cTgz8iwy3"
      },
      "source": [
        "Calculate the over all sample mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTkJW6nIizMm"
      },
      "outputs": [],
      "source": [
        "def compute_overall_mean(MUs):\n",
        "  U = np.zeros([1,10304])\n",
        "  for i in range (n_of_classes):\n",
        "    U += MUs[i]\n",
        "  U = U/n_of_classes \n",
        "  return U"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCJhXABNW_7A"
      },
      "source": [
        "*Calculate* Sb (between-class scatter matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m0X5vkpcXB_8"
      },
      "outputs": [],
      "source": [
        "def compute_sb(MUs, U, s_callback):\n",
        "  Sb = pd.DataFrame(np.zeros((10304, 10304)))\n",
        "  for i in range (n_of_classes):\n",
        "    b = MUs[i] - U\n",
        "    s = s_callback(i) * (b.T * b)\n",
        "    Sb += s\n",
        "  return Sb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUYTIbnwl_hJ"
      },
      "source": [
        "Calculate each S (within-class scatter matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYZ7Y5CYmCG-"
      },
      "outputs": [],
      "source": [
        "def compute_s(MUs, data):\n",
        "  S = pd.DataFrame(np.zeros((10304, 10304)))\n",
        "\n",
        "  for i in range (0, rows, n_of_instances):\n",
        "    d = data.iloc[i:i+n_of_instances, :]\n",
        "    # z = d - MUs[i//n_of_instances]\n",
        "    s = (n_of_instances - 1) * d.cov()\n",
        "    S += s\n",
        "  return S\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqvW29x57uGu"
      },
      "source": [
        "Calculate eigen vectors and eigen values of A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oa5F15SFFXGd"
      },
      "outputs": [],
      "source": [
        "from numpy.linalg import eig\n",
        "import scipy.linalg\n",
        "def lda_compute_eigen_values_vectors(A):\n",
        "  print(n_of_eigenvectors)\n",
        "  eigenValues, eigenVectors = scipy.linalg.eigh(A, \n",
        "                        eigvals=( (10304 - (n_of_eigenvectors + 1) ), (10304-1) ) )\n",
        "\n",
        "  # printing eigen values\n",
        "  print(\"Eigen values :\\n\", eigenValues)\n",
        "    \n",
        "  # printing eigen vectors\n",
        "  print(\"Eigen vectors of :\\n\", eigenVectors)\n",
        "  \n",
        "  #take the real parts only\n",
        "  eigenValues = eigenValues.astype(np.float64)\n",
        "  print(type(eigenValues[0]))\n",
        "\n",
        "  eigenVectors = eigenVectors.astype(np.float64)\n",
        "  print(type(eigenVectors[0][0]))\n",
        "\n",
        "  return eigenValues, eigenVectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sY9TCU4GM5_m"
      },
      "source": [
        "Calculate the projection matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pm3QKnA_M9di"
      },
      "outputs": [],
      "source": [
        "def compute_projection_matrix(eigenVectors):\n",
        "  P = eigenVectors.transpose()[:n_of_eigenvectors, :]\n",
        "  P = pd.DataFrame(P).astype(np.float64)\n",
        "  print(P.shape)\n",
        "  return P"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lda_projection(n_of_eigenvectors, A, X_train, X_test, Y_train, Y_test):\n",
        "  \n",
        "  set_n_of_eigen_vectors(n_of_eigenvectors)\n",
        "  \n",
        "  eigenValues, eigenVectors = lda_compute_eigen_values_vectors(A)\n",
        "  \n",
        "  P = compute_projection_matrix(eigenVectors)\n",
        "  \n",
        "  projected_x_train, projected_x_test = projection(P, X_train, X_test)\n",
        "  \n",
        "  predicted = knn_prediction(projected_x_train, Y_train, projected_x_test)\n",
        "  \n",
        "  print(\"Evaluation Without Tunning: \")\n",
        "  evaluation(predicted, Y_test)\n",
        "  \n",
        "  print(\"Evaluation With Tunning: \")\n",
        "  tunning(projected_x_train, Y_train, projected_x_test, Y_test)\n"
      ],
      "metadata": {
        "id": "8rY8rh3ogLkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lda(n_of_eigenvectors, split_callback):\n",
        "\n",
        "  X_train, Y_train, X_test, Y_test = data_preparation(split_callback)\n",
        "\n",
        "  MUs = calculate_means(X_train)\n",
        "\n",
        "  S = compute_s(MUs, X_train)\n",
        "\n",
        "  U = compute_overall_mean(MUs)\n",
        "\n",
        "  def s(i):\n",
        "    return n_of_instances\n",
        "  Sb = compute_sb(MUs, U, s)\n",
        "  \n",
        "  A = np.dot(np.linalg.inv(S), Sb)\n",
        "  \n",
        "  lda_projection(n_of_eigenvectors, A, X_train, X_test, Y_train, Y_test)"
      ],
      "metadata": {
        "id": "0IvjL-QkPTiA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lda(39, bonus_split)"
      ],
      "metadata": {
        "id": "LGOUmH32OO_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOzRUWu62mzU"
      },
      "source": [
        "# **Classification using PCA** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTnlI67Q4cR7"
      },
      "source": [
        "*Center The Data*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s2U9dP3DVyIf"
      },
      "outputs": [],
      "source": [
        "def center_data(data):\n",
        "  mean = data.mean(axis=0)\n",
        "  z = data - mean\n",
        "  print(z)\n",
        "  return z"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aod2fchQ4lY9"
      },
      "source": [
        "*Compute Covariance matrix*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqZsYE9QW8g5"
      },
      "outputs": [],
      "source": [
        "def compute_covariance(data):\n",
        "  cov_matrix = np.cov(data, rowvar = False, bias=True)\n",
        "  print(cov_matrix)\n",
        "  return cov_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3USYEbg4rDd"
      },
      "source": [
        "*Compute eigenvales and eigenvectors*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HImR_XMt6BUS"
      },
      "outputs": [],
      "source": [
        "def compute_eigens(cov_matrix):\n",
        "  eigen_values, eigen_vectors = np.linalg.eigh(cov_matrix)\n",
        "  for i in range(len(eigen_vectors)):\n",
        "    eigen_vectors[i] = eigen_vectors[i][::-1]\n",
        "  eigen_values = eigen_values[::-1]\n",
        "  print(eigen_values)\n",
        "  print(eigen_vectors)\n",
        "\n",
        "  #take the real parts only\n",
        "  eigen_values = eigen_values.astype(np.float64)\n",
        "  print(type(eigen_values[0]))\n",
        "\n",
        "  eigen_vectors = eigen_vectors.astype(np.float64)\n",
        "  print(type(eigen_vectors[0][0]))\n",
        "  return eigen_values, eigen_vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLOJl2AE4-ly"
      },
      "source": [
        "*Fraction of the total variance*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rlf-2P6cYBhj"
      },
      "outputs": [],
      "source": [
        "def choose_dimensionality(alpha):\n",
        "  sum = eigen_values.sum()\n",
        "  values = 0\n",
        "  r = 0\n",
        "  for value in eigen_values:\n",
        "    values += value\n",
        "    r = r + 1\n",
        "    ratio = values/sum \n",
        "    if ratio >= alpha:\n",
        "      print(r)\n",
        "      return r"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRNfxJtW5Q9h"
      },
      "source": [
        "*Reduced basis*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCGOszHEiauY"
      },
      "outputs": [],
      "source": [
        "def reduced_basis(r, eigen_vectors):\n",
        "  u = eigen_vectors\n",
        "  u = eigen_vectors[:,0:r]\n",
        "\n",
        "  return u"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8Va_jV95U_t"
      },
      "source": [
        "*Reduced Dimensionality data*"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_for_pca(data):\n",
        "  z = center_data(data)\n",
        "  cov_matrix = compute_covariance(data)\n",
        "  eigen_values, eigen_vectors = compute_eigens(cov_matrix)\n",
        "  return eigen_values, eigen_vectors"
      ],
      "metadata": {
        "id": "83gY-7HZMf4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8QMWCMvzndW7"
      },
      "outputs": [],
      "source": [
        "def PCA(data, alpha, eigen_values, eigen_vectors):\n",
        "\n",
        "  r = choose_dimensionality(alpha)\n",
        "\n",
        "  u = reduced_basis(r, eigen_vectors)\n",
        "\n",
        "  u = reduced_basis(r, eigen_vectors)\n",
        "\n",
        "  projected_x_train, projected_x_test = projection(u.transpose(), X_train, X_test)\n",
        "\n",
        "  predicted = knn_prediction(projected_x_train, Y_train, projected_x_test)\n",
        "\n",
        "  evaluation(predicted , Y_test)\n",
        "\n",
        "  tunning(projected_x_train, Y_train, projected_x_test, Y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute Different Alphas"
      ],
      "metadata": {
        "id": "Bz8B_UTiPP1W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jB05enxLHxu"
      },
      "outputs": [],
      "source": [
        "alphas = [0.8, 0.85, 0.9, 0.95]\n",
        "\n",
        "X_train, Y_train, X_test, Y_test = data_preparation(split)\n",
        "eigen_values, eigen_vectors = prepare_for_pca(X_train)\n",
        "\n",
        "for alpha in alphas :\n",
        "  PCA(X_train, alpha, eigen_values, eigen_vectors)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYuua6hebgXK"
      },
      "source": [
        "# **Projection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9p17P7urXa2R"
      },
      "source": [
        "Project X_train and X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UHtlaUNPXg7u"
      },
      "outputs": [],
      "source": [
        "def projection(P, X_train, X_test):\n",
        "  \n",
        "  # get p transpose\n",
        "  P_trans = P.transpose()\n",
        "  \n",
        "  # project x_train\n",
        "  projected_x_train = np.dot(X_train, P_trans)\n",
        "  \n",
        "  # insure the dim\n",
        "  print(projected_x_train.shape) \n",
        "  \n",
        "  # project x_test \n",
        "  projected_x_test = np.dot(X_test, P_trans)\n",
        "  \n",
        "  # insure the dim\n",
        "  print(projected_x_test.shape)\n",
        "  \n",
        "  return projected_x_train, projected_x_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiRj6rRMhHH9"
      },
      "source": [
        "Knn Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qV5SRq9hKr9"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "def knn_prediction(projected_x_train, Y_train, projected_x_test):\n",
        "  \n",
        "  knn = KNeighborsClassifier(n_neighbors=1)\n",
        "  knn.fit(projected_x_train, Y_train) \n",
        "\n",
        "  # Prediction \n",
        "  predicted = knn.predict(projected_x_test)\n",
        "  return predicted"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPDjm-juduOP"
      },
      "source": [
        "Evolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lUsntLxUdyd0"
      },
      "outputs": [],
      "source": [
        "def evaluation(predicted, y_test):\n",
        "\n",
        "    from sklearn.metrics import accuracy_score, f1_score\n",
        "    accuracy = accuracy_score(predicted , y_test)\n",
        "    f1 = f1_score(predicted , y_test , average='weighted')\n",
        "    print (\"Accuracy: \", accuracy)\n",
        "    f1 = float(\"{0:.3f}\".format(f1))\n",
        "    print(\"F1_score: \",f1)\n",
        "\n",
        "    #calculating precision and reall\n",
        "\n",
        "    from sklearn.metrics import precision_score , recall_score\n",
        "    precision = precision_score(predicted, y_test,  average='micro')\n",
        "    recall = recall_score(predicted, y_test,  average='micro' ) \n",
        "    print('Precision: ', precision)\n",
        "    print('Recall: ', recall)\n",
        "    \n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    confusion = confusion_matrix(predicted, y_test)\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ah55ls5thyy_"
      },
      "source": [
        "Model Parameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pXnFEUQihzlx"
      },
      "outputs": [],
      "source": [
        "#function input is the training data , model , params to tunes  return the best model after tunning\n",
        "# Import 'make_scorer', and 'GridSearchCV'\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.metrics import accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def fit_model(X, y , model , params):    \n",
        "    # Create cross-validation sets from the training data\n",
        "    cv_sets=ShuffleSplit(n_splits=10, random_state=42, test_size=0.3, train_size=None)\n",
        "  \n",
        "\n",
        "    #Transform 'performance_metric' into a scoring function using 'make_scorer' \n",
        "    scoring_fnc = make_scorer(accuracy_score)\n",
        "    #Create the grid search cv object --> GridSearchCV()\n",
        "    grid = GridSearchCV(estimator=model, param_grid= params, scoring=scoring_fnc,cv=cv_sets)\n",
        "    # Fit the grid search object to the data to compute the optimal model\n",
        "    grid = grid.fit(X, y)\n",
        "\n",
        "    scores = grid.cv_results_.get('mean_test_score')\n",
        "    for i in params :      \n",
        "        plt.scatter(x = params[i] ,y = scores)\n",
        "        plt.show()\n",
        "    # Return the optimal model after fitting the data\n",
        "    return grid.best_estimator_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ju98UvMsh8Uo"
      },
      "source": [
        "Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nq0jK4qHh-a1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "def tunning(projected_x_train, Y_train, projected_x_test, Y_test):\n",
        "  model = KNeighborsClassifier()\n",
        "\n",
        "  space = np.arange(1,9,2)\n",
        "\n",
        "  #  Create a dictionary for the parameter 'n_estimators' with a range from 10 to 100\n",
        "  params = {'n_neighbors':space}\n",
        "\n",
        "  #call gradient decent function to split the data into kfolds and tune the giving params\n",
        "  best_model = fit_model(projected_x_train, Y_train, model, params)\n",
        "  print(\"the best n_neighbors :\" , best_model.get_params()['n_neighbors'])\n",
        "  #Predict the response for test dataset\n",
        "  predicted = best_model.predict(projected_x_test)\n",
        "\n",
        "  #evaluating\n",
        "  evaluation(predicted, Y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Compare vs Non-Face Images - Binary Classification**"
      ],
      "metadata": {
        "id": "VgI0ofGuVSUx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = []\n",
        "ratio = []\n",
        "\n",
        "# LDA (number of eigen vectors) : 1, 10, 20, 30, 40, 50, 60, 70, 100\n",
        "\n",
        "# Teat 1 : Ratio 1    -    Faces = 200, Non-Faces = 200\n",
        "# Test 2 : Ratio 0.75 -    Faces = 200, Non-Faces = 150\n",
        "# Test 3 : Ratio 0.5  -    Faces = 200, Non-Faces = 100\n",
        "# Test 4 : Ratio 0.25 -    Faces = 200, Non-Faces = 50\n",
        "\n",
        "non_faces_numbers = [200, 150, 100, 50]\n",
        "n_of_eigenvectors = [1, 10, 20, 30, 40, 50, 60, 70, 100] "
      ],
      "metadata": {
        "id": "eeZVjEb7n-qI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import io\n",
        "zf = zipfile.ZipFile('pgm.zip')\n",
        "zf.extractall('pgm')"
      ],
      "metadata": {
        "id": "lVVOI7vPWMga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read non-faces photos"
      ],
      "metadata": {
        "id": "ejvoATza6HQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "\n",
        "def load_non_faces_images(folder):\n",
        "    images = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img = cv2.imread(os.path.join(folder, filename), 0)\n",
        "        if img is not None:\n",
        "            images.append(img)\n",
        "    return images"
      ],
      "metadata": {
        "id": "YtbzDpDV6KTi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bviTCMzj0y1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_non_faces_data(df_non, df):\n",
        "  # Split Non-Faces Data\n",
        "  X_non_test = df_non.iloc[::2]\n",
        "  X_non_train = df_non.iloc[1::2]\n",
        "\n",
        "  # Split Faces Data\n",
        "  X_faces_test = df.iloc[::2]\n",
        "  X_faces_train = df.iloc[1::2]\n",
        "\n",
        "  return X_non_test, X_non_train, X_faces_test, X_faces_train"
      ],
      "metadata": {
        "id": "vYFXzg2liJMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def non_faces_data_preparation(n_rows):\n",
        "\n",
        "  dataset = read_images()\n",
        "  images = load_non_faces_images('/content/pgm/pgm/')\n",
        "\n",
        "  data = flatten_images(400, dataset)\n",
        "  non_faces_data = flatten_images(n_rows*2, images)\n",
        "  print(len(images))\n",
        "\n",
        "  df = pd.DataFrame(data=data)\n",
        "  df_non = pd.DataFrame(data=non_faces_data)\n",
        "\n",
        "  X_non_test, X_non_train, X_faces_test, X_faces_train = split_non_faces_data(df_non, df)\n",
        "\n",
        "  df = pd.concat([X_non_train, X_faces_train])\n",
        "  \n",
        "  MUs = calculate_means(df)\n",
        "  S = compute_s(MUs, df)\n",
        "\n",
        "  return MUs, S, shuffle_data(X_non_train, X_non_test, X_faces_train, X_faces_test)"
      ],
      "metadata": {
        "id": "xlzVcfum6knU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lda_intial(n_rows, data_preparation):\n",
        "\n",
        "  intialize_variables(n_rows + 200, 2, 0)\n",
        "\n",
        "  MUs, S, X_train, Y_train, X_test, Y_test = data_preparation(n_rows)\n",
        "  \n",
        "  U = compute_overall_mean(MUs)\n",
        "\n",
        "  instances = [n_rows, 200]\n",
        "  def s_instances(i):\n",
        "    return instances[i] \n",
        "  \n",
        "  Sb = compute_sb(MUs, U, s_instances)\n",
        "  \n",
        "  A = np.dot(np.linalg.inv(S), Sb)\n",
        "  \n",
        "  return A, X_train, Y_train, X_test, Y_test"
      ],
      "metadata": {
        "id": "TilTywbwzqvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A, X_train, Y_train, X_test, Y_test = lda_intial(200, non_faces_data_preparation)\n",
        "lda_projection(70, A, X_train, X_test, Y_train, Y_test)"
      ],
      "metadata": {
        "id": "UJ59e1k1Hz_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in [1, 10, 20, 30, 40, 50, 60, 70, 100] :\n",
        "  print(\"Number of Eigen vectors : \" + str(i))\n",
        "  lda_projection(i, A, X_train, X_test, Y_train, Y_test)\n",
        "  "
      ],
      "metadata": {
        "id": "1x8hN7_jS_Xj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in [80, 90, 150, 200, 300]:\n",
        "  lda_projection(i, A, X_train, X_test, Y_train, Y_test)"
      ],
      "metadata": {
        "id": "AQ6NmrxmnX-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in [200, 150, 100, 50]:\n",
        "  A, X_train, Y_train, X_test, Y_test = lda_intial(i, non_faces_compute_mean, non_faces_compute_s)\n",
        "  lda_projection(70, A, X_train, X_test, Y_train, Y_test)"
      ],
      "metadata": {
        "id": "lF8qlJshtahJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        " \n",
        "# x axis values\n",
        "x = [400, 300, 200, 100]\n",
        "# corresponding y axis values\n",
        "y = [0.925, 0.9028, 0.923, 0.952]\n",
        " \n",
        " \n",
        "# naming the x axis\n",
        "plt.xlabel('Number of Non-faces images (Faces = 400) ')\n",
        "# naming the y axis\n",
        "plt.ylabel('Accuracy')\n",
        " \n",
        "# giving a title to my graph\n",
        "plt.scatter(x, y, label= \"stars\", color= \"green\", s=50) \n",
        "# function to show the plot\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xP2czquf4yO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Labels Identification "
      ],
      "metadata": {
        "id": "J80mveYPmTLS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def label_identification(X_non_train, X_non_test, X_faces_train, X_faces_test):\n",
        "  X_non_train[len(X_non_train.columns)] = 0\n",
        "  X_non_test[len(X_non_test.columns)] = 0\n",
        "\n",
        "  X_faces_train[len(X_faces_train.columns)] = 1\n",
        "  X_faces_test[len(X_faces_test.columns)] = 1\n",
        "\n",
        "  return X_non_test, X_non_train, X_faces_test, X_faces_train"
      ],
      "metadata": {
        "id": "TBQ8kUXXmReS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_identification()"
      ],
      "metadata": {
        "id": "tO7q5PVHZh15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_shuffle(df_1, df_2):  \n",
        "  df = pd.concat([df_1, df_2])\n",
        "  df = df.sample(frac=1).reset_index(drop=True)\n",
        "  return df"
      ],
      "metadata": {
        "id": "vPiBwMUyogdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def shuffle_data(X_non_train, X_non_test, X_faces_train, X_faces_test):\n",
        "  X_non_test, X_non_train, X_faces_test, X_faces_train = label_identification(X_non_train, X_non_test, X_faces_train, X_faces_test)\n",
        "  X_train = merge_shuffle(X_non_train, X_faces_train)\n",
        "  X_test = merge_shuffle(X_non_test, X_faces_test) \n",
        "\n",
        "  Y_train = X_train.iloc[:,-1:]\n",
        "  X_train.drop(X_train.columns[len(X_train.columns)-1], axis=1, inplace=True)\n",
        "\n",
        "  Y_test = X_test.iloc[:,-1:]\n",
        "  X_test.drop(X_test.columns[len(X_test.columns)-1], axis=1, inplace=True)\n",
        "  return X_train, Y_train, X_test, Y_test"
      ],
      "metadata": {
        "id": "4p_Se7VNo4zG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Face Recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "OYuua6hebgXK"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}